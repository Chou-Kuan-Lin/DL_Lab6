{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T01:14:17.786347Z",
     "start_time": "2019-08-29T01:14:15.095882Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import gym\n",
    "import numpy\n",
    "import torch.optim\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T01:14:18.363018Z",
     "start_time": "2019-08-29T01:14:18.326038Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "environment = gym.make('Pendulum-v0')\n",
    "NUM_ACTIONS = environment.action_space.shape[0]\n",
    "NUM_STATES = environment.observation_space.shape[0]\n",
    "\n",
    "LEARNING_RATE_ACTOR = 0.0001\n",
    "LEARNING_RATE_CRITIC = 0.001\n",
    "TAU = 0.001\n",
    "BATCH_SIZE = 64\n",
    "MEMORY_CAPACITY = 10000\n",
    "GAMMA = 0.99\n",
    "TRAIN_EPISODE = 1000\n",
    "TEST_EPISODE = 10\n",
    "VAR = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T01:16:57.678117Z",
     "start_time": "2019-08-29T01:16:57.622149Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class\n",
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self, state, action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(state, 400)\n",
    "        self.linear2 = torch.nn.Linear(400, 300)\n",
    "        self.linear3 = torch.nn.Linear(300, action)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Critic(torch.nn.Module):\n",
    "    def __init__(self, state, action):\n",
    "        super(Critic, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(state, 400)\n",
    "        self.linear2 = torch.nn.Linear(400 + action, 300)\n",
    "        self.linear3 = torch.nn.Linear(300, 1)\n",
    "        self.linear4 = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x, act):\n",
    "        # front\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = torch.cat([x, act.type_as(x)], 1)\n",
    "\n",
    "        # end\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Agent(object):\n",
    "    def __init__(self, state, action, var):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "\n",
    "        self.actor = Actor(self.state, self.action)\n",
    "        self.critic = Critic(self.state, self.action)\n",
    "        self.actorTarget = Actor(self.state, self.action)\n",
    "        self.criticTarget = Critic(self.state, self.action)\n",
    "\n",
    "        self.actorOptimizer = torch.optim.Adam(\n",
    "            self.actor.parameters(), lr=LEARNING_RATE_ACTOR)\n",
    "        self.criticOptimizer = torch.optim.Adam(\n",
    "            self.critic.parameters(), lr=LEARNING_RATE_CRITIC)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.buffer = []\n",
    "        self.var = var\n",
    "        self.memoryCounter = 0\n",
    "        self.memory = numpy.zeros((MEMORY_CAPACITY, NUM_STATES * 2 + 2))\n",
    "\n",
    "    def chooseAction(self, state0):\n",
    "        state0 = torch.tensor(state0, dtype=torch.float)\n",
    "        action = self.actor(state0)\n",
    "\n",
    "        action = action.cpu().data.numpy()\n",
    "        action = numpy.clip(numpy.random.normal(action, self.var), -1, 1)\n",
    "        return action\n",
    "\n",
    "    def storeTransition(self, state, action, reward, state2):\n",
    "        transition = numpy.hstack((state, [action, reward], state2))\n",
    "        index = self.memoryCounter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memoryCounter += 1\n",
    "\n",
    "    def softUpdate(self, target, source):\n",
    "        for t, s in zip(target.parameters(), source.parameters()):\n",
    "            t.data.copy_((1.0 - TAU) * t.data + TAU * s.data)\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memoryCounter <= 5000:\n",
    "            return\n",
    "\n",
    "        if self.memoryCounter > MEMORY_CAPACITY:\n",
    "            sample_index = numpy.random.choice(\n",
    "                MEMORY_CAPACITY, size=BATCH_SIZE)\n",
    "        else:\n",
    "            sample_index = numpy.random.choice(\n",
    "                self.memoryCounter, size=BATCH_SIZE)\n",
    "\n",
    "        batchMemory = self.memory[sample_index, :]\n",
    "        batchState = torch.FloatTensor(batchMemory[:, :NUM_STATES])\n",
    "        batchAction = torch.LongTensor(\n",
    "            batchMemory[:, NUM_STATES:NUM_STATES + NUM_ACTIONS])\n",
    "        batchReward = torch.FloatTensor(\n",
    "            batchMemory[:, -NUM_STATES - 1:-NUM_STATES])\n",
    "        batchState2 = torch.FloatTensor(batchMemory[:, -NUM_STATES:])\n",
    "\n",
    "        batchAction2 = self.actorTarget(batchState2)\n",
    "\n",
    "        qTarget = batchReward + GAMMA * self.criticTarget(\n",
    "            batchState2, batchAction2).detach()\n",
    "        qPredict = self.critic(batchState, batchAction)\n",
    "\n",
    "        # update critic\n",
    "        self.criticOptimizer.zero_grad()\n",
    "        criticLoss = self.criterion(qPredict, qTarget)\n",
    "        criticLoss.backward()\n",
    "        self.criticOptimizer.step()\n",
    "\n",
    "        # update actor\n",
    "        self.actorOptimizer.zero_grad()\n",
    "        action = self.actor(batchState)  # action prediction\n",
    "        actorLoss = -self.critic(batchState, action)  # max -> Q for prediction\n",
    "        actorLoss = actorLoss.mean()\n",
    "        actorLoss.backward()\n",
    "        self.actorOptimizer.step()\n",
    "\n",
    "        self.softUpdate(self.criticTarget, self.critic)\n",
    "        self.softUpdate(self.actorTarget, self.actor)\n",
    "\n",
    "        self.var *= 0.9995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:59:55.753011Z",
     "start_time": "2019-08-29T01:17:09.131582Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------TRAINING----------\n",
      "[ 0 ] -1814.39\n",
      "[ 1 ] -1068.55\n",
      "[ 2 ] -777.6\n",
      "[ 3 ] -1347.09\n",
      "[ 4 ] -861.94\n",
      "[ 5 ] -1372.56\n",
      "[ 6 ] -1392.38\n",
      "[ 7 ] -1057.3\n",
      "[ 8 ] -1586.2\n",
      "[ 9 ] -1598.21\n",
      "[ 10 ] -1321.86\n",
      "[ 11 ] -1805.87\n",
      "[ 12 ] -1527.48\n",
      "[ 13 ] -1570.61\n",
      "[ 14 ] -1055.54\n",
      "[ 15 ] -756.52\n",
      "[ 16 ] -1115.64\n",
      "[ 17 ] -1657.87\n",
      "[ 18 ] -1469.42\n",
      "[ 19 ] -890.92\n",
      "[ 20 ] -1388.43\n",
      "[ 21 ] -904.94\n",
      "[ 22 ] -1732.98\n",
      "[ 23 ] -769.29\n",
      "[ 24 ] -750.5\n",
      "[ 25 ] -1413.21\n",
      "[ 26 ] -1583.21\n",
      "[ 27 ] -1461.3\n",
      "[ 28 ] -1404.06\n",
      "[ 29 ] -1384.53\n",
      "[ 30 ] -1095.44\n",
      "[ 31 ] -1800.43\n",
      "[ 32 ] -1177.29\n",
      "[ 33 ] -1011.25\n",
      "[ 34 ] -1410.8\n",
      "[ 35 ] -1436.42\n",
      "[ 36 ] -925.29\n",
      "[ 37 ] -1065.12\n",
      "[ 38 ] -1802.47\n",
      "[ 39 ] -1049.98\n",
      "[ 40 ] -1322.6\n",
      "[ 41 ] -1599.98\n",
      "[ 42 ] -1757.57\n",
      "[ 43 ] -1302.53\n",
      "[ 44 ] -1708.8\n",
      "[ 45 ] -1625.7\n",
      "[ 46 ] -835.74\n",
      "[ 47 ] -1168.49\n",
      "[ 48 ] -1276.41\n",
      "[ 49 ] -1613.27\n",
      "[ 50 ] -1434.52\n",
      "[ 51 ] -1661.46\n",
      "[ 52 ] -979.46\n",
      "[ 53 ] -1305.37\n",
      "[ 54 ] -1341.28\n",
      "[ 55 ] -1294.93\n",
      "[ 56 ] -1097.75\n",
      "[ 57 ] -1209.34\n",
      "[ 58 ] -1286.82\n",
      "[ 59 ] -1321.44\n",
      "[ 60 ] -1060.71\n",
      "[ 61 ] -1347.26\n",
      "[ 62 ] -1006.47\n",
      "[ 63 ] -1357.99\n",
      "[ 64 ] -1178.82\n",
      "[ 65 ] -1353.29\n",
      "[ 66 ] -1633.05\n",
      "[ 67 ] -934.65\n",
      "[ 68 ] -1343.21\n",
      "[ 69 ] -1023.98\n",
      "[ 70 ] -1367.08\n",
      "[ 71 ] -1173.4\n",
      "[ 72 ] -1778.81\n",
      "[ 73 ] -1745.55\n",
      "[ 74 ] -1719.82\n",
      "[ 75 ] -1457.55\n",
      "[ 76 ] -1359.96\n",
      "[ 77 ] -1788.85\n",
      "[ 78 ] -1049.75\n",
      "[ 79 ] -1152.32\n",
      "[ 80 ] -1622.54\n",
      "[ 81 ] -1342.95\n",
      "[ 82 ] -1380.05\n",
      "[ 83 ] -1462.84\n",
      "[ 84 ] -1207.92\n",
      "[ 85 ] -1672.9\n",
      "[ 86 ] -1172.04\n",
      "[ 87 ] -923.97\n",
      "[ 88 ] -1338.22\n",
      "[ 89 ] -1344.68\n",
      "[ 90 ] -1173.57\n",
      "[ 91 ] -1835.09\n",
      "[ 92 ] -1353.11\n",
      "[ 93 ] -1686.43\n",
      "[ 94 ] -1036.51\n",
      "[ 95 ] -1140.27\n",
      "[ 96 ] -1655.54\n",
      "[ 97 ] -1356.43\n",
      "[ 98 ] -1346.69\n",
      "[ 99 ] -1343.24\n",
      "[ 100 ] -1198.94\n",
      "[ 101 ] -1675.09\n",
      "[ 102 ] -1356.75\n",
      "[ 103 ] -1548.37\n",
      "[ 104 ] -1066.28\n",
      "[ 105 ] -1774.82\n",
      "[ 106 ] -1281.99\n",
      "[ 107 ] -1360.12\n",
      "[ 108 ] -1167.34\n",
      "[ 109 ] -1356.62\n",
      "[ 110 ] -1048.44\n",
      "[ 111 ] -1406.83\n",
      "[ 112 ] -910.64\n",
      "[ 113 ] -1348.06\n",
      "[ 114 ] -1302.89\n",
      "[ 115 ] -1161.05\n",
      "[ 116 ] -1340.13\n",
      "[ 117 ] -1347.61\n",
      "[ 118 ] -1358.95\n",
      "[ 119 ] -1361.17\n",
      "[ 120 ] -1342.96\n",
      "[ 121 ] -1353.5\n",
      "[ 122 ] -952.72\n",
      "[ 123 ] -1157.39\n",
      "[ 124 ] -1654.53\n",
      "[ 125 ] -1692.32\n",
      "[ 126 ] -952.37\n",
      "[ 127 ] -1287.84\n",
      "[ 128 ] -1060.84\n",
      "[ 129 ] -1330.77\n",
      "[ 130 ] -1337.91\n",
      "[ 131 ] -1483.05\n",
      "[ 132 ] -1346.1\n",
      "[ 133 ] -1171.64\n",
      "[ 134 ] -1351.49\n",
      "[ 135 ] -1799.4\n",
      "[ 136 ] -1188.23\n",
      "[ 137 ] -1657.13\n",
      "[ 138 ] -1209.91\n",
      "[ 139 ] -1004.72\n",
      "[ 140 ] -1181.51\n",
      "[ 141 ] -1462.66\n",
      "[ 142 ] -1280.04\n",
      "[ 143 ] -1527.64\n",
      "[ 144 ] -1316.66\n",
      "[ 145 ] -1348.46\n",
      "[ 146 ] -1742.19\n",
      "[ 147 ] -953.21\n",
      "[ 148 ] -1798.92\n",
      "[ 149 ] -1175.04\n",
      "[ 150 ] -854.03\n",
      "[ 151 ] -1378.02\n",
      "[ 152 ] -1024.68\n",
      "[ 153 ] -1351.29\n",
      "[ 154 ] -1196.22\n",
      "[ 155 ] -1211.44\n",
      "[ 156 ] -1043.69\n",
      "[ 157 ] -1174.57\n",
      "[ 158 ] -1357.75\n",
      "[ 159 ] -1783.18\n",
      "[ 160 ] -943.39\n",
      "[ 161 ] -1379.81\n",
      "[ 162 ] -1730.31\n",
      "[ 163 ] -1251.13\n",
      "[ 164 ] -1343.7\n",
      "[ 165 ] -1348.94\n",
      "[ 166 ] -1333.29\n",
      "[ 167 ] -1347.96\n",
      "[ 168 ] -1204.29\n",
      "[ 169 ] -1071.84\n",
      "[ 170 ] -1359.36\n",
      "[ 171 ] -1266.35\n",
      "[ 172 ] -1071.57\n",
      "[ 173 ] -1753.75\n",
      "[ 174 ] -1051.24\n",
      "[ 175 ] -1203.11\n",
      "[ 176 ] -1265.62\n",
      "[ 177 ] -1360.45\n",
      "[ 178 ] -867.98\n",
      "[ 179 ] -1205.29\n",
      "[ 180 ] -1319.24\n",
      "[ 181 ] -1041.99\n",
      "[ 182 ] -1785.24\n",
      "[ 183 ] -1188.12\n",
      "[ 184 ] -1561.93\n",
      "[ 185 ] -1313.35\n",
      "[ 186 ] -1844.63\n",
      "[ 187 ] -1793.88\n",
      "[ 188 ] -1361.75\n",
      "[ 189 ] -1359.66\n",
      "[ 190 ] -1060.41\n",
      "[ 191 ] -1213.55\n",
      "[ 192 ] -1234.22\n",
      "[ 193 ] -1705.6\n",
      "[ 194 ] -1305.0\n",
      "[ 195 ] -1174.38\n",
      "[ 196 ] -1729.66\n",
      "[ 197 ] -1630.01\n",
      "[ 198 ] -1240.38\n",
      "[ 199 ] -1198.42\n",
      "[ 200 ] -1017.57\n",
      "[ 201 ] -1484.43\n",
      "[ 202 ] -1293.65\n",
      "[ 203 ] -1000.95\n",
      "[ 204 ] -1207.38\n",
      "[ 205 ] -1287.5\n",
      "[ 206 ] -1359.77\n",
      "[ 207 ] -1236.7\n",
      "[ 208 ] -1342.76\n",
      "[ 209 ] -1146.81\n",
      "[ 210 ] -1277.47\n",
      "[ 211 ] -1344.49\n",
      "[ 212 ] -953.91\n",
      "[ 213 ] -1364.56\n",
      "[ 214 ] -1342.29\n",
      "[ 215 ] -1354.5\n",
      "[ 216 ] -1619.62\n",
      "[ 217 ] -950.34\n",
      "[ 218 ] -1185.48\n",
      "[ 219 ] -847.8\n",
      "[ 220 ] -1178.14\n",
      "[ 221 ] -1284.87\n",
      "[ 222 ] -1459.98\n",
      "[ 223 ] -1183.32\n",
      "[ 224 ] -1171.42\n",
      "[ 225 ] -1017.05\n",
      "[ 226 ] -1329.94\n",
      "[ 227 ] -1302.64\n",
      "[ 228 ] -1358.6\n",
      "[ 229 ] -1344.63\n",
      "[ 230 ] -961.02\n",
      "[ 231 ] -1343.97\n",
      "[ 232 ] -1710.1\n",
      "[ 233 ] -1353.93\n",
      "[ 234 ] -1331.55\n",
      "[ 235 ] -1174.64\n",
      "[ 236 ] -1283.56\n",
      "[ 237 ] -1276.52\n",
      "[ 238 ] -1479.64\n",
      "[ 239 ] -1369.69\n",
      "[ 240 ] -1407.36\n",
      "[ 241 ] -1347.03\n",
      "[ 242 ] -966.88\n",
      "[ 243 ] -1197.86\n",
      "[ 244 ] -1359.01\n",
      "[ 245 ] -1473.91\n",
      "[ 246 ] -1491.28\n",
      "[ 247 ] -1030.77\n",
      "[ 248 ] -1334.75\n",
      "[ 249 ] -1197.82\n",
      "[ 250 ] -1461.17\n",
      "[ 251 ] -1662.74\n",
      "[ 252 ] -980.21\n",
      "[ 253 ] -1345.76\n",
      "[ 254 ] -1357.45\n",
      "[ 255 ] -1425.62\n",
      "[ 256 ] -1032.36\n",
      "[ 257 ] -1214.85\n",
      "[ 258 ] -1266.58\n",
      "[ 259 ] -1353.21\n",
      "[ 260 ] -1349.75\n",
      "[ 261 ] -953.34\n",
      "[ 262 ] -1844.92\n",
      "[ 263 ] -960.61\n",
      "[ 264 ] -1177.6\n",
      "[ 265 ] -1353.46\n",
      "[ 266 ] -1447.02\n",
      "[ 267 ] -1160.39\n",
      "[ 268 ] -953.65\n",
      "[ 269 ] -1354.05\n",
      "[ 270 ] -1072.05\n",
      "[ 271 ] -1354.48\n",
      "[ 272 ] -1331.73\n",
      "[ 273 ] -1188.48\n",
      "[ 274 ] -1289.45\n",
      "[ 275 ] -953.59\n",
      "[ 276 ] -1156.35\n",
      "[ 277 ] -1049.36\n",
      "[ 278 ] -1192.84\n",
      "[ 279 ] -1335.78\n",
      "[ 280 ] -1789.26\n",
      "[ 281 ] -1342.96\n",
      "[ 282 ] -1355.97\n",
      "[ 283 ] -1351.17\n",
      "[ 284 ] -1343.14\n",
      "[ 285 ] -985.1\n",
      "[ 286 ] -1357.14\n",
      "[ 287 ] -1263.89\n",
      "[ 288 ] -1758.26\n",
      "[ 289 ] -1341.84\n",
      "[ 290 ] -1299.12\n",
      "[ 291 ] -1229.78\n",
      "[ 292 ] -1309.06\n",
      "[ 293 ] -1633.71\n",
      "[ 294 ] -1221.35\n",
      "[ 295 ] -1039.55\n",
      "[ 296 ] -1582.43\n",
      "[ 297 ] -1240.75\n",
      "[ 298 ] -1375.55\n",
      "[ 299 ] -1469.9\n",
      "[ 300 ] -1653.89\n",
      "[ 301 ] -1677.99\n",
      "[ 302 ] -1460.85\n",
      "[ 303 ] -1330.45\n",
      "[ 304 ] -1368.12\n",
      "[ 305 ] -1502.42\n",
      "[ 306 ] -1202.28\n",
      "[ 307 ] -1663.2\n",
      "[ 308 ] -970.67\n",
      "[ 309 ] -977.69\n",
      "[ 310 ] -1019.41\n",
      "[ 311 ] -1198.35\n",
      "[ 312 ] -1346.83\n",
      "[ 313 ] -1275.92\n",
      "[ 314 ] -1003.8\n",
      "[ 315 ] -1111.85\n",
      "[ 316 ] -1794.17\n",
      "[ 317 ] -1377.82\n",
      "[ 318 ] -1350.43\n",
      "[ 319 ] -1172.12\n",
      "[ 320 ] -1319.56\n",
      "[ 321 ] -1177.53\n",
      "[ 322 ] -1229.99\n",
      "[ 323 ] -1350.09\n",
      "[ 324 ] -1768.18\n",
      "[ 325 ] -1180.53\n",
      "[ 326 ] -1345.27\n",
      "[ 327 ] -1329.73\n",
      "[ 328 ] -1056.19\n",
      "[ 329 ] -1841.29\n",
      "[ 330 ] -1743.33\n",
      "[ 331 ] -1780.16\n",
      "[ 332 ] -1247.04\n",
      "[ 333 ] -952.04\n",
      "[ 334 ] -1396.02\n",
      "[ 335 ] -1284.28\n",
      "[ 336 ] -1775.84\n",
      "[ 337 ] -1052.42\n",
      "[ 338 ] -1842.82\n",
      "[ 339 ] -1483.5\n",
      "[ 340 ] -1352.96\n",
      "[ 341 ] -953.46\n",
      "[ 342 ] -1322.15\n",
      "[ 343 ] -1545.75\n",
      "[ 344 ] -1339.12\n",
      "[ 345 ] -1351.79\n",
      "[ 346 ] -1310.64\n",
      "[ 347 ] -1822.68\n",
      "[ 348 ] -1564.41\n",
      "[ 349 ] -1160.58\n",
      "[ 350 ] -848.24\n",
      "[ 351 ] -1834.56\n",
      "[ 352 ] -1255.6\n",
      "[ 353 ] -885.79\n",
      "[ 354 ] -1304.71\n",
      "[ 355 ] -1489.15\n",
      "[ 356 ] -1257.54\n",
      "[ 357 ] -1065.63\n",
      "[ 358 ] -1169.05\n",
      "[ 359 ] -1324.57\n",
      "[ 360 ] -1702.2\n",
      "[ 361 ] -1209.44\n",
      "[ 362 ] -1215.98\n",
      "[ 363 ] -1188.9\n",
      "[ 364 ] -1391.55\n",
      "[ 365 ] -1329.58\n",
      "[ 366 ] -1346.7\n",
      "[ 367 ] -1314.36\n",
      "[ 368 ] -1714.53\n",
      "[ 369 ] -1319.85\n",
      "[ 370 ] -1249.07\n",
      "[ 371 ] -1667.78\n",
      "[ 372 ] -1539.19\n",
      "[ 373 ] -1060.03\n",
      "[ 374 ] -1178.71\n",
      "[ 375 ] -1314.36\n",
      "[ 376 ] -1335.38\n",
      "[ 377 ] -1480.74\n",
      "[ 378 ] -1298.67\n",
      "[ 379 ] -1277.71\n",
      "[ 380 ] -852.99\n",
      "[ 381 ] -1540.07\n",
      "[ 382 ] -1052.91\n",
      "[ 383 ] -1347.43\n",
      "[ 384 ] -1361.33\n",
      "[ 385 ] -1332.31\n",
      "[ 386 ] -1357.83\n",
      "[ 387 ] -953.72\n",
      "[ 388 ] -1490.56\n",
      "[ 389 ] -1062.79\n",
      "[ 390 ] -1651.77\n",
      "[ 391 ] -954.11\n",
      "[ 392 ] -1691.92\n",
      "[ 393 ] -1327.79\n",
      "[ 394 ] -1233.68\n",
      "[ 395 ] -1166.53\n",
      "[ 396 ] -1355.8\n",
      "[ 397 ] -848.84\n",
      "[ 398 ] -1361.46\n",
      "[ 399 ] -1152.89\n",
      "[ 400 ] -1367.88\n",
      "[ 401 ] -1347.41\n",
      "[ 402 ] -951.9\n",
      "[ 403 ] -1357.15\n",
      "[ 404 ] -1182.61\n",
      "[ 405 ] -1784.97\n",
      "[ 406 ] -1336.98\n",
      "[ 407 ] -1361.24\n",
      "[ 408 ] -1457.26\n",
      "[ 409 ] -1192.74\n",
      "[ 410 ] -1166.98\n",
      "[ 411 ] -1183.32\n",
      "[ 412 ] -1354.83\n",
      "[ 413 ] -1129.0\n",
      "[ 414 ] -1352.57\n",
      "[ 415 ] -897.75\n",
      "[ 416 ] -1332.68\n",
      "[ 417 ] -1201.8\n",
      "[ 418 ] -1155.21\n",
      "[ 419 ] -1802.1\n",
      "[ 420 ] -1206.0\n",
      "[ 421 ] -1063.62\n",
      "[ 422 ] -1316.93\n",
      "[ 423 ] -1158.44\n",
      "[ 424 ] -1352.69\n",
      "[ 425 ] -865.89\n",
      "[ 426 ] -1322.03\n",
      "[ 427 ] -1338.47\n",
      "[ 428 ] -1261.15\n",
      "[ 429 ] -1166.21\n",
      "[ 430 ] -1019.82\n",
      "[ 431 ] -1114.71\n",
      "[ 432 ] -1348.9\n",
      "[ 433 ] -1140.47\n",
      "[ 434 ] -947.22\n",
      "[ 435 ] -1413.97\n",
      "[ 436 ] -1744.98\n",
      "[ 437 ] -1059.7\n",
      "[ 438 ] -1842.9\n",
      "[ 439 ] -1359.13\n",
      "[ 440 ] -1174.98\n",
      "[ 441 ] -992.63\n",
      "[ 442 ] -1655.16\n",
      "[ 443 ] -1296.67\n",
      "[ 444 ] -1214.93\n",
      "[ 445 ] -852.05\n",
      "[ 446 ] -1351.23\n",
      "[ 447 ] -1055.66\n",
      "[ 448 ] -1069.67\n",
      "[ 449 ] -1331.03\n",
      "[ 450 ] -1151.51\n",
      "[ 451 ] -1179.94\n",
      "[ 452 ] -1350.74\n",
      "[ 453 ] -1453.19\n",
      "[ 454 ] -1159.93\n",
      "[ 455 ] -1756.81\n",
      "[ 456 ] -1169.33\n",
      "[ 457 ] -1345.92\n",
      "[ 458 ] -1351.24\n",
      "[ 459 ] -1345.81\n",
      "[ 460 ] -1335.41\n",
      "[ 461 ] -1330.59\n",
      "[ 462 ] -1365.44\n",
      "[ 463 ] -1346.57\n",
      "[ 464 ] -1794.13\n",
      "[ 465 ] -1602.59\n",
      "[ 466 ] -1012.36\n",
      "[ 467 ] -1013.6\n",
      "[ 468 ] -975.85\n",
      "[ 469 ] -1333.04\n",
      "[ 470 ] -1062.09\n",
      "[ 471 ] -1305.31\n",
      "[ 472 ] -1351.95\n",
      "[ 473 ] -1174.53\n",
      "[ 474 ] -1755.18\n",
      "[ 475 ] -1064.35\n",
      "[ 476 ] -1177.39\n",
      "[ 477 ] -1682.88\n",
      "[ 478 ] -1328.03\n",
      "[ 479 ] -1350.56\n",
      "[ 480 ] -1343.6\n",
      "[ 481 ] -1349.71\n",
      "[ 482 ] -1189.46\n",
      "[ 483 ] -1207.18\n",
      "[ 484 ] -1343.93\n",
      "[ 485 ] -1716.01\n",
      "[ 486 ] -1229.81\n",
      "[ 487 ] -1507.94\n",
      "[ 488 ] -1751.26\n",
      "[ 489 ] -1166.27\n",
      "[ 490 ] -1474.57\n",
      "[ 491 ] -1059.88\n",
      "[ 492 ] -1175.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 493 ] -1504.84\n",
      "[ 494 ] -1479.6\n",
      "[ 495 ] -1350.21\n",
      "[ 496 ] -1362.72\n",
      "[ 497 ] -1827.02\n",
      "[ 498 ] -1690.91\n",
      "[ 499 ] -907.71\n",
      "[ 500 ] -1066.78\n",
      "[ 501 ] -1180.55\n",
      "[ 502 ] -1501.76\n",
      "[ 503 ] -1348.57\n",
      "[ 504 ] -1022.72\n",
      "[ 505 ] -1668.58\n",
      "[ 506 ] -1363.9\n",
      "[ 507 ] -1354.65\n",
      "[ 508 ] -1350.04\n",
      "[ 509 ] -1296.84\n",
      "[ 510 ] -1355.3\n",
      "[ 511 ] -1637.92\n",
      "[ 512 ] -1361.1\n",
      "[ 513 ] -1466.26\n",
      "[ 514 ] -1345.92\n",
      "[ 515 ] -1258.53\n",
      "[ 516 ] -1278.91\n",
      "[ 517 ] -1779.56\n",
      "[ 518 ] -837.1\n",
      "[ 519 ] -1193.82\n",
      "[ 520 ] -1062.92\n",
      "[ 521 ] -1813.0\n",
      "[ 522 ] -1035.85\n",
      "[ 523 ] -1193.84\n",
      "[ 524 ] -1755.49\n",
      "[ 525 ] -1347.22\n",
      "[ 526 ] -1351.07\n",
      "[ 527 ] -1067.49\n",
      "[ 528 ] -1347.85\n",
      "[ 529 ] -1298.61\n",
      "[ 530 ] -888.87\n",
      "[ 531 ] -1258.54\n",
      "[ 532 ] -1290.94\n",
      "[ 533 ] -1508.69\n",
      "[ 534 ] -952.27\n",
      "[ 535 ] -1123.2\n",
      "[ 536 ] -1158.19\n",
      "[ 537 ] -1090.13\n",
      "[ 538 ] -1269.33\n",
      "[ 539 ] -1459.77\n",
      "[ 540 ] -1492.12\n",
      "[ 541 ] -1195.86\n",
      "[ 542 ] -1650.79\n",
      "[ 543 ] -1334.9\n",
      "[ 544 ] -1354.84\n",
      "[ 545 ] -1357.47\n",
      "[ 546 ] -1342.42\n",
      "[ 547 ] -1421.6\n",
      "[ 548 ] -1652.0\n",
      "[ 549 ] -1343.0\n",
      "[ 550 ] -1065.71\n",
      "[ 551 ] -988.55\n",
      "[ 552 ] -1735.31\n",
      "[ 553 ] -972.81\n",
      "[ 554 ] -1276.08\n",
      "[ 555 ] -1262.57\n",
      "[ 556 ] -1777.89\n",
      "[ 557 ] -1519.08\n",
      "[ 558 ] -1750.13\n",
      "[ 559 ] -977.73\n",
      "[ 560 ] -1632.3\n",
      "[ 561 ] -1354.81\n",
      "[ 562 ] -1310.88\n",
      "[ 563 ] -1341.45\n",
      "[ 564 ] -1032.97\n",
      "[ 565 ] -1335.62\n",
      "[ 566 ] -1286.3\n",
      "[ 567 ] -1119.23\n",
      "[ 568 ] -1343.73\n",
      "[ 569 ] -1644.91\n",
      "[ 570 ] -1607.78\n",
      "[ 571 ] -1701.62\n",
      "[ 572 ] -1286.2\n",
      "[ 573 ] -1434.8\n",
      "[ 574 ] -954.08\n",
      "[ 575 ] -1338.98\n",
      "[ 576 ] -1364.93\n",
      "[ 577 ] -948.55\n",
      "[ 578 ] -1593.05\n",
      "[ 579 ] -1164.62\n",
      "[ 580 ] -1733.84\n",
      "[ 581 ] -1018.74\n",
      "[ 582 ] -1334.31\n",
      "[ 583 ] -1260.77\n",
      "[ 584 ] -1842.27\n",
      "[ 585 ] -1785.3\n",
      "[ 586 ] -1792.9\n",
      "[ 587 ] -1317.58\n",
      "[ 588 ] -1548.83\n",
      "[ 589 ] -1511.78\n",
      "[ 590 ] -1178.22\n",
      "[ 591 ] -1205.66\n",
      "[ 592 ] -1162.22\n",
      "[ 593 ] -1503.4\n",
      "[ 594 ] -1317.55\n",
      "[ 595 ] -1199.34\n",
      "[ 596 ] -1322.07\n",
      "[ 597 ] -1353.17\n",
      "[ 598 ] -1116.91\n",
      "[ 599 ] -1478.45\n",
      "[ 600 ] -1064.09\n",
      "[ 601 ] -1347.1\n",
      "[ 602 ] -1384.87\n",
      "[ 603 ] -1097.66\n",
      "[ 604 ] -1843.88\n",
      "[ 605 ] -1343.73\n",
      "[ 606 ] -1443.1\n",
      "[ 607 ] -1192.78\n",
      "[ 608 ] -1168.2\n",
      "[ 609 ] -1048.87\n",
      "[ 610 ] -1480.28\n",
      "[ 611 ] -1361.6\n",
      "[ 612 ] -1563.76\n",
      "[ 613 ] -1346.18\n",
      "[ 614 ] -1306.9\n",
      "[ 615 ] -1336.7\n",
      "[ 616 ] -1632.34\n",
      "[ 617 ] -1353.32\n",
      "[ 618 ] -1015.9\n",
      "[ 619 ] -1071.15\n",
      "[ 620 ] -1593.04\n",
      "[ 621 ] -1352.09\n",
      "[ 622 ] -1443.12\n",
      "[ 623 ] -1445.77\n",
      "[ 624 ] -1357.85\n",
      "[ 625 ] -1009.58\n",
      "[ 626 ] -1731.51\n",
      "[ 627 ] -1057.32\n",
      "[ 628 ] -1342.14\n",
      "[ 629 ] -952.79\n",
      "[ 630 ] -1374.72\n",
      "[ 631 ] -1721.83\n",
      "[ 632 ] -1278.63\n",
      "[ 633 ] -1629.14\n",
      "[ 634 ] -1344.06\n",
      "[ 635 ] -1362.1\n",
      "[ 636 ] -953.86\n",
      "[ 637 ] -1197.68\n",
      "[ 638 ] -1353.41\n",
      "[ 639 ] -1605.74\n",
      "[ 640 ] -953.24\n",
      "[ 641 ] -1444.38\n",
      "[ 642 ] -929.64\n",
      "[ 643 ] -1346.96\n",
      "[ 644 ] -1600.08\n",
      "[ 645 ] -1601.68\n",
      "[ 646 ] -1263.19\n",
      "[ 647 ] -1440.03\n",
      "[ 648 ] -1299.16\n",
      "[ 649 ] -1183.46\n",
      "[ 650 ] -1568.67\n",
      "[ 651 ] -1667.79\n",
      "[ 652 ] -1283.78\n",
      "[ 653 ] -1173.55\n",
      "[ 654 ] -1531.53\n",
      "[ 655 ] -1497.86\n",
      "[ 656 ] -1159.19\n",
      "[ 657 ] -1091.66\n",
      "[ 658 ] -1615.53\n",
      "[ 659 ] -1727.53\n",
      "[ 660 ] -1347.13\n",
      "[ 661 ] -1588.84\n",
      "[ 662 ] -1348.74\n",
      "[ 663 ] -1340.17\n",
      "[ 664 ] -1062.71\n",
      "[ 665 ] -1172.18\n",
      "[ 666 ] -1355.39\n",
      "[ 667 ] -1172.63\n",
      "[ 668 ] -1174.14\n",
      "[ 669 ] -1208.55\n",
      "[ 670 ] -1056.47\n",
      "[ 671 ] -1522.15\n",
      "[ 672 ] -950.07\n",
      "[ 673 ] -1058.2\n",
      "[ 674 ] -1666.13\n",
      "[ 675 ] -1068.41\n",
      "[ 676 ] -1354.97\n",
      "[ 677 ] -1811.15\n",
      "[ 678 ] -1356.21\n",
      "[ 679 ] -1063.01\n",
      "[ 680 ] -1346.32\n",
      "[ 681 ] -1165.21\n",
      "[ 682 ] -1334.57\n",
      "[ 683 ] -1347.94\n",
      "[ 684 ] -1035.75\n",
      "[ 685 ] -1145.74\n",
      "[ 686 ] -1327.6\n",
      "[ 687 ] -1252.64\n",
      "[ 688 ] -957.87\n",
      "[ 689 ] -1103.73\n",
      "[ 690 ] -1502.66\n",
      "[ 691 ] -1608.33\n",
      "[ 692 ] -1440.9\n",
      "[ 693 ] -1350.15\n",
      "[ 694 ] -1359.77\n",
      "[ 695 ] -1347.99\n",
      "[ 696 ] -1061.17\n",
      "[ 697 ] -1284.11\n",
      "[ 698 ] -1321.05\n",
      "[ 699 ] -1317.47\n",
      "[ 700 ] -1719.83\n",
      "[ 701 ] -1116.72\n",
      "[ 702 ] -1352.8\n",
      "[ 703 ] -1550.51\n",
      "[ 704 ] -1361.3\n",
      "[ 705 ] -1323.11\n",
      "[ 706 ] -1345.42\n",
      "[ 707 ] -1053.14\n",
      "[ 708 ] -1541.08\n",
      "[ 709 ] -1268.72\n",
      "[ 710 ] -900.31\n",
      "[ 711 ] -1191.37\n",
      "[ 712 ] -1528.58\n",
      "[ 713 ] -1185.0\n",
      "[ 714 ] -1182.23\n",
      "[ 715 ] -1601.98\n",
      "[ 716 ] -1046.86\n",
      "[ 717 ] -1729.84\n",
      "[ 718 ] -1723.08\n",
      "[ 719 ] -1351.9\n",
      "[ 720 ] -1115.06\n",
      "[ 721 ] -1360.5\n",
      "[ 722 ] -1193.64\n",
      "[ 723 ] -1434.6\n",
      "[ 724 ] -1658.76\n",
      "[ 725 ] -951.38\n",
      "[ 726 ] -1091.7\n",
      "[ 727 ] -834.2\n",
      "[ 728 ] -1634.04\n",
      "[ 729 ] -1071.73\n",
      "[ 730 ] -1529.98\n",
      "[ 731 ] -1047.3\n",
      "[ 732 ] -1339.42\n",
      "[ 733 ] -1636.18\n",
      "[ 734 ] -1345.38\n",
      "[ 735 ] -1428.19\n",
      "[ 736 ] -1437.98\n",
      "[ 737 ] -1394.72\n",
      "[ 738 ] -1220.53\n",
      "[ 739 ] -1537.71\n",
      "[ 740 ] -1614.24\n",
      "[ 741 ] -1344.04\n",
      "[ 742 ] -1066.03\n",
      "[ 743 ] -1174.17\n",
      "[ 744 ] -1207.19\n",
      "[ 745 ] -1319.13\n",
      "[ 746 ] -1334.61\n",
      "[ 747 ] -1427.33\n",
      "[ 748 ] -1363.61\n",
      "[ 749 ] -1302.33\n",
      "[ 750 ] -1351.48\n",
      "[ 751 ] -1342.13\n",
      "[ 752 ] -1335.08\n",
      "[ 753 ] -1794.18\n",
      "[ 754 ] -1514.86\n",
      "[ 755 ] -1615.37\n",
      "[ 756 ] -1334.16\n",
      "[ 757 ] -1346.57\n",
      "[ 758 ] -1342.68\n",
      "[ 759 ] -1315.72\n",
      "[ 760 ] -1608.88\n",
      "[ 761 ] -957.34\n",
      "[ 762 ] -1624.68\n",
      "[ 763 ] -1356.21\n",
      "[ 764 ] -1061.72\n",
      "[ 765 ] -1344.97\n",
      "[ 766 ] -1337.35\n",
      "[ 767 ] -1329.74\n",
      "[ 768 ] -1728.4\n",
      "[ 769 ] -1068.95\n",
      "[ 770 ] -1573.06\n",
      "[ 771 ] -1612.32\n",
      "[ 772 ] -1403.68\n",
      "[ 773 ] -1551.08\n",
      "[ 774 ] -1171.28\n",
      "[ 775 ] -1362.89\n",
      "[ 776 ] -1331.4\n",
      "[ 777 ] -1685.71\n",
      "[ 778 ] -860.16\n",
      "[ 779 ] -1355.79\n",
      "[ 780 ] -1334.16\n",
      "[ 781 ] -1358.63\n",
      "[ 782 ] -1308.7\n",
      "[ 783 ] -1482.32\n",
      "[ 784 ] -1339.87\n",
      "[ 785 ] -1355.02\n",
      "[ 786 ] -1505.46\n",
      "[ 787 ] -1348.49\n",
      "[ 788 ] -1355.36\n",
      "[ 789 ] -1741.44\n",
      "[ 790 ] -1328.19\n",
      "[ 791 ] -1384.28\n",
      "[ 792 ] -1304.61\n",
      "[ 793 ] -1397.39\n",
      "[ 794 ] -1301.89\n",
      "[ 795 ] -1364.2\n",
      "[ 796 ] -1828.08\n",
      "[ 797 ] -1060.94\n",
      "[ 798 ] -1134.22\n",
      "[ 799 ] -1342.71\n",
      "[ 800 ] -1259.52\n",
      "[ 801 ] -1758.88\n",
      "[ 802 ] -1355.99\n",
      "[ 803 ] -1309.18\n",
      "[ 804 ] -985.94\n",
      "[ 805 ] -1520.02\n",
      "[ 806 ] -1316.52\n",
      "[ 807 ] -1721.28\n",
      "[ 808 ] -1144.9\n",
      "[ 809 ] -1226.72\n",
      "[ 810 ] -1358.88\n",
      "[ 811 ] -1257.69\n",
      "[ 812 ] -988.41\n",
      "[ 813 ] -968.61\n",
      "[ 814 ] -1578.67\n",
      "[ 815 ] -1053.16\n",
      "[ 816 ] -1697.92\n",
      "[ 817 ] -1177.19\n",
      "[ 818 ] -1840.68\n",
      "[ 819 ] -1169.37\n",
      "[ 820 ] -1760.93\n",
      "[ 821 ] -1359.02\n",
      "[ 822 ] -1274.39\n",
      "[ 823 ] -1371.83\n",
      "[ 824 ] -1824.83\n",
      "[ 825 ] -1029.19\n",
      "[ 826 ] -1059.59\n",
      "[ 827 ] -994.03\n",
      "[ 828 ] -1602.02\n",
      "[ 829 ] -1219.35\n",
      "[ 830 ] -1656.13\n",
      "[ 831 ] -872.97\n",
      "[ 832 ] -1762.54\n",
      "[ 833 ] -1691.66\n",
      "[ 834 ] -1677.16\n",
      "[ 835 ] -1593.92\n",
      "[ 836 ] -1341.76\n",
      "[ 837 ] -1359.17\n",
      "[ 838 ] -1703.92\n",
      "[ 839 ] -852.73\n",
      "[ 840 ] -1175.7\n",
      "[ 841 ] -1300.67\n",
      "[ 842 ] -1601.63\n",
      "[ 843 ] -1319.92\n",
      "[ 844 ] -1206.08\n",
      "[ 845 ] -886.47\n",
      "[ 846 ] -1602.0\n",
      "[ 847 ] -991.07\n",
      "[ 848 ] -1330.93\n",
      "[ 849 ] -1341.84\n",
      "[ 850 ] -1358.4\n",
      "[ 851 ] -1346.43\n",
      "[ 852 ] -1063.64\n",
      "[ 853 ] -1203.04\n",
      "[ 854 ] -932.34\n",
      "[ 855 ] -1136.86\n",
      "[ 856 ] -1352.26\n",
      "[ 857 ] -1162.62\n",
      "[ 858 ] -1350.85\n",
      "[ 859 ] -1161.37\n",
      "[ 860 ] -1270.87\n",
      "[ 861 ] -1222.93\n",
      "[ 862 ] -1060.88\n",
      "[ 863 ] -1345.32\n",
      "[ 864 ] -1348.28\n",
      "[ 865 ] -1306.89\n",
      "[ 866 ] -1064.59\n",
      "[ 867 ] -1328.2\n",
      "[ 868 ] -1359.73\n",
      "[ 869 ] -1332.63\n",
      "[ 870 ] -1319.36\n",
      "[ 871 ] -1204.34\n",
      "[ 872 ] -1816.2\n",
      "[ 873 ] -1348.83\n",
      "[ 874 ] -1502.7\n",
      "[ 875 ] -1107.5\n",
      "[ 876 ] -1377.26\n",
      "[ 877 ] -1355.69\n",
      "[ 878 ] -1078.26\n",
      "[ 879 ] -1332.78\n",
      "[ 880 ] -1285.39\n",
      "[ 881 ] -1731.64\n",
      "[ 882 ] -1180.79\n",
      "[ 883 ] -1351.3\n",
      "[ 884 ] -1353.93\n",
      "[ 885 ] -1515.66\n",
      "[ 886 ] -933.19\n",
      "[ 887 ] -1346.43\n",
      "[ 888 ] -1179.65\n",
      "[ 889 ] -1327.18\n",
      "[ 890 ] -1581.97\n",
      "[ 891 ] -1361.2\n",
      "[ 892 ] -1293.8\n",
      "[ 893 ] -1391.84\n",
      "[ 894 ] -1059.2\n",
      "[ 895 ] -1362.41\n",
      "[ 896 ] -1351.13\n",
      "[ 897 ] -1785.93\n",
      "[ 898 ] -1755.86\n",
      "[ 899 ] -1347.32\n",
      "[ 900 ] -1339.62\n",
      "[ 901 ] -1209.15\n",
      "[ 902 ] -972.22\n",
      "[ 903 ] -1337.7\n",
      "[ 904 ] -1444.71\n",
      "[ 905 ] -1194.42\n",
      "[ 906 ] -953.43\n",
      "[ 907 ] -1345.21\n",
      "[ 908 ] -1804.51\n",
      "[ 909 ] -1340.1\n",
      "[ 910 ] -1731.91\n",
      "[ 911 ] -1215.58\n",
      "[ 912 ] -1029.21\n",
      "[ 913 ] -1197.06\n",
      "[ 914 ] -1354.66\n",
      "[ 915 ] -1043.07\n",
      "[ 916 ] -1383.2\n",
      "[ 917 ] -1355.78\n",
      "[ 918 ] -1346.95\n",
      "[ 919 ] -1422.11\n",
      "[ 920 ] -943.62\n",
      "[ 921 ] -1359.65\n",
      "[ 922 ] -1259.6\n",
      "[ 923 ] -1341.82\n",
      "[ 924 ] -1353.66\n",
      "[ 925 ] -956.55\n",
      "[ 926 ] -1435.55\n",
      "[ 927 ] -1464.9\n",
      "[ 928 ] -1183.26\n",
      "[ 929 ] -1571.2\n",
      "[ 930 ] -1324.08\n",
      "[ 931 ] -1180.05\n",
      "[ 932 ] -1109.9\n",
      "[ 933 ] -1164.58\n",
      "[ 934 ] -1688.39\n",
      "[ 935 ] -1341.61\n",
      "[ 936 ] -1511.92\n",
      "[ 937 ] -1616.52\n",
      "[ 938 ] -1311.98\n",
      "[ 939 ] -1717.73\n",
      "[ 940 ] -1188.45\n",
      "[ 941 ] -1355.45\n",
      "[ 942 ] -1059.14\n",
      "[ 943 ] -1164.94\n",
      "[ 944 ] -1307.44\n",
      "[ 945 ] -1708.67\n",
      "[ 946 ] -946.53\n",
      "[ 947 ] -1364.42\n",
      "[ 948 ] -1075.58\n",
      "[ 949 ] -1348.62\n",
      "[ 950 ] -1298.84\n",
      "[ 951 ] -1168.93\n",
      "[ 952 ] -1304.31\n",
      "[ 953 ] -1478.44\n",
      "[ 954 ] -1567.82\n",
      "[ 955 ] -1063.66\n",
      "[ 956 ] -1356.8\n",
      "[ 957 ] -1360.36\n",
      "[ 958 ] -1312.37\n",
      "[ 959 ] -1324.76\n",
      "[ 960 ] -1270.03\n",
      "[ 961 ] -1269.75\n",
      "[ 962 ] -1060.61\n",
      "[ 963 ] -1210.88\n",
      "[ 964 ] -1343.74\n",
      "[ 965 ] -1561.69\n",
      "[ 966 ] -1208.73\n",
      "[ 967 ] -1492.15\n",
      "[ 968 ] -1821.51\n",
      "[ 969 ] -1236.0\n",
      "[ 970 ] -1517.21\n",
      "[ 971 ] -1314.12\n",
      "[ 972 ] -952.9\n",
      "[ 973 ] -1455.08\n",
      "[ 974 ] -1576.11\n",
      "[ 975 ] -1194.2\n",
      "[ 976 ] -1349.55\n",
      "[ 977 ] -1648.54\n",
      "[ 978 ] -1171.53\n",
      "[ 979 ] -1549.66\n",
      "[ 980 ] -1339.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 981 ] -1598.23\n",
      "[ 982 ] -1798.97\n",
      "[ 983 ] -1706.57\n",
      "[ 984 ] -1183.52\n",
      "[ 985 ] -1739.47\n",
      "[ 986 ] -1249.61\n",
      "[ 987 ] -1161.6\n",
      "[ 988 ] -1443.85\n",
      "[ 989 ] -1366.09\n",
      "[ 990 ] -1669.3\n",
      "[ 991 ] -837.97\n",
      "[ 992 ] -1091.04\n",
      "[ 993 ] -1301.47\n",
      "[ 994 ] -1272.43\n",
      "[ 995 ] -1780.82\n",
      "[ 996 ] -1305.11\n",
      "[ 997 ] -1059.94\n",
      "[ 998 ] -1512.49\n",
      "[ 999 ] -1356.16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b7304535dfb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoreArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoreArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"#0000FF\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoreArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeanArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeanArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# main\n",
    "ddpg = Agent(NUM_STATES, NUM_ACTIONS, VAR)\n",
    "\n",
    "for times in range(1):\n",
    "\n",
    "    # training\n",
    "    print('----------TRAINING----------')\n",
    "    scoreArray = []\n",
    "    meanArray = []\n",
    "    for i in range(TRAIN_EPISODE):\n",
    "        state = environment.reset()\n",
    "        totalReward = 0\n",
    "        while True:\n",
    "            action = ddpg.chooseAction(state)\n",
    "\n",
    "            state2, reward, done, info = environment.step(action)\n",
    "\n",
    "            reward = -1 if done else reward\n",
    "\n",
    "            ddpg.storeTransition(state, action, reward, state2)\n",
    "\n",
    "            totalReward += reward\n",
    "            ddpg.learn()\n",
    "\n",
    "            if done:\n",
    "                print('[', i, ']', round(totalReward, 2))\n",
    "                break\n",
    "\n",
    "            state = state2\n",
    "\n",
    "        scoreArray.append(totalReward)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            meanArray.append(sum(scoreArray[-100:]) / 100)\n",
    "\n",
    "    # plot\n",
    "    matplotlib.pyplot.figure(figsize=(10, 6))\n",
    "    matplotlib.pyplot.plot(list(range(0, len(scoreArray))), scoreArray, color=\"#0000FF\")\n",
    "    matplotlib.pyplot.plot(list(range(0, len(scoreArray), len(meanArray))), meanArray)\n",
    "    matplotlib.pyplot.title('Pendulum')\n",
    "    matplotlib.pyplot.xlabel('EPISODE')\n",
    "    matplotlib.pyplot.ylabel('REWARD')\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    # testing\n",
    "    print('----------TESTING----------')\n",
    "    scoreArray = []\n",
    "    for i in range(TEST_EPISODE):\n",
    "        state = environment.reset()\n",
    "        totalReward = 0\n",
    "\n",
    "        while True:\n",
    "            action = ddpg.chooseAction(state)\n",
    "            state2, reward, done, info = environment.step(action)\n",
    "\n",
    "            totalReward += reward\n",
    "\n",
    "            if done:\n",
    "                print('[', i, ']', totalReward)\n",
    "                break\n",
    "\n",
    "            state = state2\n",
    "        scoreArray.append(totalReward)\n",
    "\n",
    "    # show result\n",
    "    print('MEANS', ((sum(scoreArray) / len(scoreArray)) + 700) / 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
